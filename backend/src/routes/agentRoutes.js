import express from 'express';
import { GoogleGenerativeAI } from '@google/generative-ai';

const router = express.Router();

// Check API key at startup
const API_KEY = process.env.API_GEMINI || process.env.GEMINI_API_KEY || '';
if (!API_KEY) {
    console.warn('‚ö†Ô∏è AVISO: Nenhuma API key do Gemini encontrada! Verifique API_GEMINI ou GEMINI_API_KEY no .env');
} else {
    console.log('‚úÖ API key do Gemini configurada (primeiros chars:', API_KEY.substring(0, 10) + '...)');
}

// Initialize Gemini
const genAI = new GoogleGenerativeAI(API_KEY);

// Business categories templates
const BUSINESS_TEMPLATES = {
    restaurante: 'Crie um agente para um restaurante que apresente o card√°pio, fa√ßa pedidos e aceite pagamentos',
    pizzaria: 'Crie um agente para uma pizzaria com tamanhos P, M, G, que colete endere√ßo e aceite pagamento',
    barbearia: 'Crie um agente para uma barbearia que agende hor√°rios e mostre servi√ßos dispon√≠veis',
    loja: 'Crie um agente para uma loja que apresente produtos, pre√ßos e fa√ßa vendas',
    ecommerce: 'Crie um agente para e-commerce que tire d√∫vidas sobre produtos e direcione para compra',
    imobiliaria: 'Crie um agente imobili√°rio que apresente im√≥veis, agende visitas e capture leads',
    consultorio: 'Crie um agente para consult√≥rio que agende consultas e tire d√∫vidas sobre procedimentos',
    escola: 'Crie um agente para escola que informe sobre cursos, valores e fa√ßa matr√≠culas',
    advocacia: 'Crie um agente para escrit√≥rio de advocacia que tire d√∫vidas e agende consultas',
    cafeteria: 'Crie um agente para cafeteria que apresente o menu e fa√ßa pedidos',
    academia: 'Crie um agente para academia que informe planos, valores e agende aulas experimentais',
    design: 'Crie um agente para est√∫dio de design que apresente portf√≥lio e fa√ßa or√ßamentos',
};

// Extract information from user prompt using Gemini
router.post('/extract', async (req, res) => {
    try {
        const { prompt } = req.body;

        if (!prompt) {
            return res.status(400).json({ success: false, error: 'Prompt √© obrigat√≥rio' });
        }

        if (!API_KEY) {
            return res.status(500).json({
                success: false,
                error: 'API key do Gemini n√£o configurada. Adicione API_GEMINI ou GEMINI_API_KEY no .env'
            });
        }

        console.log('üìù Extraindo informa√ß√µes do prompt:', prompt);

        const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

        const extractionPrompt = `Analise o seguinte texto e extraia as informa√ß√µes para criar um agente de vendas.
Retorne APENAS um JSON v√°lido (sem markdown, sem \`\`\`) com a seguinte estrutura:

{
    "business_type": "tipo do neg√≥cio (ex: pizzaria, loja, barbearia)",
    "business_name": "nome do neg√≥cio se mencionado, ou null",
    "products": [
        { "name": "nome do produto", "price": "pre√ßo se mencionado" }
    ],
    "payment_methods": ["m√©todos de pagamento mencionados"],
    "integrations": ["integra√ß√µes mencionadas (agenda, endere√ßo, whatsapp, etc)"],
    "tone": "tom de comunica√ß√£o sugerido",
    "detected_tags": [
        { "text": "texto detectado", "type": "price|payment|integration|product" }
    ]
}

Texto para analisar:
"${prompt}"`;

        const result = await model.generateContent(extractionPrompt);
        const response = await result.response;
        const text = response.text();

        console.log('ü§ñ Resposta do Gemini:', text);

        // Parse JSON response
        let extractedInfo;
        try {
            // Remove markdown code blocks if present
            const cleanText = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
            extractedInfo = JSON.parse(cleanText);
        } catch (parseError) {
            console.error('Erro ao parsear JSON:', parseError);
            extractedInfo = {
                business_type: 'neg√≥cio',
                products: [],
                payment_methods: [],
                integrations: [],
                detected_tags: []
            };
        }

        console.log('‚úÖ Informa√ß√µes extra√≠das:', extractedInfo);

        res.json({
            success: true,
            data: extractedInfo
        });

    } catch (error) {
        console.error('‚ùå Erro na extra√ß√£o:', error);
        res.status(500).json({
            success: false,
            error: 'Erro ao processar com Gemini',
            details: error.message
        });
    }
});

// Generate final sales agent prompt
router.post('/generate', async (req, res) => {
    try {
        const { extractedInfo, originalPrompt } = req.body;

        if (!extractedInfo) {
            return res.status(400).json({ success: false, error: 'Informa√ß√µes extra√≠das s√£o obrigat√≥rias' });
        }

        console.log('üéØ Gerando prompt de vendas...');

        const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

        const generationPrompt = `Crie um prompt de sistema para um agente de vendas de WhatsApp baseado nas seguintes informa√ß√µes:

Tipo de neg√≥cio: ${extractedInfo.business_type}
Nome do neg√≥cio: ${extractedInfo.business_name || 'n√£o especificado'}
Produtos: ${JSON.stringify(extractedInfo.products)}
M√©todos de pagamento: ${extractedInfo.payment_methods?.join(', ') || 'n√£o especificado'}
Integra√ß√µes: ${extractedInfo.integrations?.join(', ') || 'nenhuma'}
Tom: ${extractedInfo.tone || 'amig√°vel e profissional'}

Descri√ß√£o original do usu√°rio: "${originalPrompt}"

O prompt deve:
1. Ser em portugu√™s brasileiro
2. Ser focado em VENDAS e convers√£o
3. Incluir os pre√ßos dos produtos
4. Instruir sobre m√©todos de pagamento
5. Ser persuasivo mas n√£o invasivo
6. Ter no m√°ximo 500 palavras

Retorne APENAS o prompt, sem explica√ß√µes adicionais.`;

        const result = await model.generateContent(generationPrompt);
        const response = await result.response;
        const agentPrompt = response.text();

        console.log('‚úÖ Prompt de vendas gerado!');
        console.log('='.repeat(50));
        console.log(agentPrompt);
        console.log('='.repeat(50));

        res.json({
            success: true,
            prompt: agentPrompt,
            extractedInfo
        });

    } catch (error) {
        console.error('‚ùå Erro na gera√ß√£o:', error);
        res.status(500).json({
            success: false,
            error: 'Erro ao gerar prompt',
            details: error.message
        });
    }
});

// Get business templates
router.get('/templates', (req, res) => {
    res.json({
        success: true,
        templates: BUSINESS_TEMPLATES
    });
});

// Interview endpoint - The AI interviewer
router.post('/interview', async (req, res) => {
    try {
        const { messages, currentInfo } = req.body;

        if (!API_KEY) {
            return res.status(500).json({ success: false, error: 'API key n√£o configurada' });
        }

        const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

        // System prompt for the Interviewer Persona
        const systemPrompt = `Voc√™ √© o "Gerador de Agentes" da Factoria.
Seu objetivo √© entrevistar o usu√°rio para coletar informa√ß√µes e criar um agente de vendas perfeito para o neg√≥cio dele.

INFORMA√á√ïES J√Å COLETADAS:
${JSON.stringify(currentInfo, null, 2)}

HIST√ìRICO DA CONVERSA:
${messages.map(m => `${m.role}: ${m.content}`).join('\n')}

SUAS INSTRU√á√ïES:
1. Analise o hist√≥rico e veja o que ainda falta descobrir (Nicho, Nome, Produtos, Pre√ßos, Hor√°rios, Diferenciais).
2. Fa√ßa UMA pergunta por vez. Seja conciso e amig√°vel.
3. Se o usu√°rio j√° informou o nicho (ex: pizzaria), fa√ßa perguntas espec√≠ficas desse nicho (ex: "Quais os sabores mais vendidos?" ou "Voc√™s t√™m tamanhos P, M e G?").
4. Se voc√™ j√° tem informa√ß√µes suficientes para criar um BOM agente (pelo menos Nome, Nicho e alguns Produtos/Servi√ßos), voc√™ DEVE sugerir finalizar.
   - Para finalizar, sua resposta DEVE come√ßar EXATAMENTE com: "√ìtimo! Tenho tudo que preciso."
5. N√ÉO seja repetitivo. Se o usu√°rio j√° falou o nome, n√£o pergunte de novo.

Responda APENAS com sua pr√≥xima fala para o usu√°rio.`;

        const result = await model.generateContent(systemPrompt);
        const response = await result.response;
        const text = response.text().trim();

        // Check if interview is complete based on AI response
        const isComplete = text.startsWith("√ìtimo! Tenho tudo que preciso");

        // Extract structured info update from the latest user message context (simulation)
        // In a real generic app we might want a second LLM call here just to extract info data structure
        // But to save latency, we will let the frontend extract logic or do a lightweight extraction here if needed.
        // For now, we will trust the "extraction" endpoint to be called at the END.
        // OR we can do a parallel extraction. Let's do a lightweight parallel extraction to keep 'currentInfo' updated.

        let updatedInfo = currentInfo || {};
        try {
            const lastUserMessage = messages[messages.length - 1];
            if (lastUserMessage && lastUserMessage.role === 'user') {
                const extractionPrompt = `Extraia informa√ß√µes deste texto para um JSON: "${lastUserMessage.content}".
                 Campos poss√≠veis: business_name, business_type, products (lista), prices, tone, hours.
                 Mantenha o que j√° existe: ${JSON.stringify(currentInfo)}.
                 Retorne apenas JSON.`;

                const extractionResult = await model.generateContent(extractionPrompt);
                const extractionText = extractionResult.response.text().replace(/```json\n?|```/g, '').trim();
                const newInfo = JSON.parse(extractionText);
                updatedInfo = { ...currentInfo, ...newInfo };
            }
        } catch (e) {
            console.error('Erro na extra√ß√£o leve:', e);
            // Ignore extraction errors and keep going
        }

        res.json({
            success: true,
            message: text,
            isComplete,
            updatedInfo
        });

    } catch (error) {
        console.error('‚ùå Erro na entrevista:', error);
        res.status(500).json({ success: false, error: 'Erro no processamento da entrevista' });
    }
});

// Test endpoint - Chat with the created agent
router.post('/chat', async (req, res) => {
    try {
        const { message, systemPrompt } = req.body;

        if (!API_KEY) return res.status(500).json({ error: 'API key ausente' });

        const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

        const chat = model.startChat({
            history: [
                { role: "user", parts: [{ text: "System Instruction: " + systemPrompt }] },
                { role: "model", parts: [{ text: "Entendido. Seguirei essas instru√ß√µes." }] }
            ],
            generationConfig: {
                maxOutputTokens: 500,
            },
        });

        const result = await chat.sendMessage(message);
        const response = await result.response;
        const text = response.text();

        res.json({
            success: true,
            message: text
        });

    } catch (error) {
        console.error('‚ùå Erro no chat de teste:', error);
        res.status(500).json({ success: false, error: 'Erro no chat' });
    }
});

export default router;
